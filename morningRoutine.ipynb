{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a251fea4-385e-4ed2-b8d1-742695b25042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk \n",
    "import tkinter.filedialog as fd\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from threading import Thread\n",
    "import datetime\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "root = tk.Tk()\n",
    "\n",
    "def open_looker_button():\n",
    "    \n",
    "    def open_looker_file():\n",
    "        filenames = fd.askopenfilenames()\n",
    "        if filenames:\n",
    "            dir_name = fd.askdirectory()\n",
    "            if dir_name:\n",
    "                tk.messagebox.showinfo(\"File loaded\",\"Press OK to start processing. This might take a minute.\")\n",
    "                df = pd.DataFrame()\n",
    "                for filename in filenames:\n",
    "                    df_new = pd.read_excel(filename,dtype='object',na_filter = False)\n",
    "                    df = pd.concat([df,df_new],ignore_index=True)\n",
    "                if 'Subdomain' in df.columns:\n",
    "                    source = 'collect_'\n",
    "                else:\n",
    "                    source = 'rms_'\n",
    "\n",
    "                save_file = dir_name + '/' + source + 'Booklist_' + str(datetime.date.today()) + '.xlsx'\n",
    "                df = list_builder(df,save_file)    \n",
    "                tk.messagebox.showinfo(\"Your file is ready!\", \"Your file was saved as: \"+save_file+\".\\n You can exit or select more files to process\")\n",
    "            else:\n",
    "                tk.messagebox.showinfo(\"Process cancelled\",\"No directory selected\")\n",
    "        else:\n",
    "            tk.messagebox.showinfo(\"Process cancelled\",\"No file selected\")\n",
    "    open_looker_file()\n",
    "    \n",
    "def open_fmf_button():\n",
    "    def fmf_mm():\n",
    "        filename = fd.askopenfilename()\n",
    "        if filename:            \n",
    "            dir_name = fd.askdirectory()            \n",
    "            if dir_name:\n",
    "                tk.messagebox.showinfo(\"File loaded\",\"Press OK to start processing. This might take a minute.\")\n",
    "                df = pd.read_excel(filename,dtype='object',na_filter = False)\n",
    "                save_file = dir_name + '/fmf_mm' + str(datetime.date.today()) + '.xlsx'\n",
    "                df = match(df,save_file)\n",
    "                tk.messagebox.showinfo(\"Your file is ready!\", \"Your file was saved as: \"+save_file+\".\\n You can exit or select more files to process\")\n",
    "            else:\n",
    "                tk.messagebox.showinfo(\"Process cancelled\",\"No directory selected\")\n",
    "        else:\n",
    "            tk.messagebox.showinfo(\"Process cancelled\",\"No file selected\")\n",
    "    fmf_mm()\n",
    "\n",
    "def list_builder(df,save_file):\n",
    "    \n",
    "    if 'Subdomain' in df.columns:\n",
    "        coll = df\n",
    "        coll = coll.iloc[:,1:]\n",
    "        coll = coll.drop_duplicates(subset=['Isbn'], keep='first')\n",
    "        coll['keep'] = 'no'\n",
    "        regex = r'[1-9]'\n",
    "        coll.replace('', 'unknown', inplace=True)\n",
    "        for index, row in coll.iterrows():\n",
    "            isbn = row['Isbn']\n",
    "            if re.search(regex, isbn):\n",
    "                coll.at[index,'keep'] = 'yes'\n",
    "\n",
    "        coll = coll.drop(coll[coll['keep'] == 'no'].index)\n",
    "        coll = coll.drop(columns=['keep'])\n",
    "        coll = coll.rename(columns={\n",
    "            'Subdomain':'Section number',\n",
    "            'Isbn':'Identifiers (VBID, ISBN or Product SKU - Required)',\n",
    "            'Authors':'Author full name'})\n",
    "\n",
    "        template_columns =[\n",
    "            'Author first name',\n",
    "            'Author last name',\n",
    "            'Publication date (mm/yyyy)',\n",
    "            'Language',\n",
    "            'Format',\n",
    "            'Duration',\n",
    "            'Course code',\n",
    "            'Enrollment',\n",
    "            'Content deadline',\n",
    "            'Launch date',\n",
    "            'Price',\n",
    "            'Currency',\n",
    "            'Courseware',\n",
    "            'Wants IA Price'\n",
    "        ]\n",
    "\n",
    "        column_index = 0\n",
    "        while column_index < len(template_columns):\n",
    "            coll[template_columns[column_index]] = ''\n",
    "            column_index += 1\n",
    "        coll_cols = list(coll.columns)\n",
    "        coll_cols.insert(12, coll_cols.pop(coll_cols.index('Section number')))\n",
    "        coll_cols.insert(0, coll_cols.pop(coll_cols.index('Identifiers (VBID, ISBN or Product SKU - Required)')))\n",
    "        coll_cols.insert(1, coll_cols.pop(coll_cols.index('Publisher')))\n",
    "        coll_cols.insert(2, coll_cols.pop(coll_cols.index('Title')))\n",
    "        coll_cols.insert(3, coll_cols.pop(coll_cols.index('Edition')))\n",
    "        coll = coll[coll_cols]\n",
    "        today = datetime.datetime.today()\n",
    "        template_date = today + datetime.timedelta(days=30)\n",
    "        coll['Course code'] = 'coll'\n",
    "        coll['Content deadline'] = template_date.strftime('%m/%d/%y')\n",
    "        coll['Launch date'] = template_date.strftime('%m/%d/%y')\n",
    "        coll['Enrollment'] = '25'\n",
    "        coll[\"Content deadline\"] = pd.to_datetime(coll[\"Content deadline\"]).dt.normalize()\n",
    "        coll[\"Launch date\"] = pd.to_datetime(coll[\"Launch date\"]).dt.normalize()\n",
    "        coll[\"Content deadline\"] = coll[\"Content deadline\"].astype(str)\n",
    "        coll[\"Launch date\"] = coll[\"Launch date\"].astype(str)\n",
    "        template = pd.read_excel('resources/Booklist_SearchTemplate.xlsx')\n",
    "        coll_upload = pd.DataFrame(np.concatenate([template, coll.values]), columns=template.columns)        \n",
    "        coll_upload.to_excel(save_file, engine='xlsxwriter', index=False) \n",
    "    else:\n",
    "        rms = df \n",
    "        rms = rms.drop_duplicates(subset=['Isbn'], keep='first') \n",
    "        rms = rms.iloc[:,1:]\n",
    "        rms = rms.drop_duplicates(subset=['Isbn'], keep='first')\n",
    "        rms['keep'] = 'no'\n",
    "        regex = r'[1-9]'\n",
    "        for index, row in rms.iterrows():\n",
    "            isbn = row['Isbn']\n",
    "            if re.search(regex, isbn):\n",
    "                rms.at[index,'keep'] = 'yes'\n",
    "            if row['Est. Sales (RMS)'] == '':\n",
    "                rms.at[index,'Est. Sales (RMS)'] = 25\n",
    "            elif row['Est. Sales (RMS)'] < 1:\n",
    "                rms.at[index,'Est. Sales (RMS)'] = 25\n",
    "        rms.replace('', 'unknown', inplace=True)\n",
    "        rms = rms.drop(rms[rms['keep'] == 'no'].index)\n",
    "        rms = rms.drop(columns=['keep'])\n",
    "        rms = rms.rename(columns={\n",
    "            'Organization Name':'Section number',\n",
    "            'Isbn':'Identifiers (VBID, ISBN or Product SKU - Required)',\n",
    "            'Author':'Author full name'})\n",
    "        template_columns =[\n",
    "            'Author first name',\n",
    "            'Author last name',\n",
    "            'Publication date (mm/yyyy)',\n",
    "            'Language',\n",
    "            'Format',\n",
    "            'Duration',\n",
    "            'Course code',\n",
    "            'Enrollment',\n",
    "            'Content deadline',\n",
    "            'Launch date',\n",
    "            'Price',\n",
    "            'Currency',\n",
    "            'Courseware',\n",
    "            'Wants IA Price'\n",
    "        ]\n",
    "        column_index = 0\n",
    "        while column_index < len(template_columns):\n",
    "            rms[template_columns[column_index]] = ''\n",
    "            column_index += 1\n",
    "        rms = rms.drop(columns=['Enrollment'])\n",
    "        rms = rms.rename(columns={'Est. Sales (RMS)':'Enrollment'})\n",
    "        rms_cols = list(rms.columns)\n",
    "        rms_cols.insert(13, rms_cols.pop(rms_cols.index('Section number')))\n",
    "        rms_cols.insert(0, rms_cols.pop(rms_cols.index('Identifiers (VBID, ISBN or Product SKU - Required)')))\n",
    "        rms_cols.insert(1, rms_cols.pop(rms_cols.index('Publisher')))\n",
    "        rms_cols.insert(2, rms_cols.pop(rms_cols.index('Title')))\n",
    "        rms_cols.insert(3, rms_cols.pop(rms_cols.index('Edition')))\n",
    "        rms_cols.insert(4, rms_cols.pop(rms_cols.index('Author full name')))\n",
    "        rms_cols.insert(13, rms_cols.pop(rms_cols.index('Enrollment')))\n",
    "        rms = rms[rms_cols]\n",
    "        today = datetime.datetime.today()\n",
    "        template_date = today + datetime.timedelta(days=30)\n",
    "        rms['Course code'] = 'rms'\n",
    "        rms['Content deadline'] = template_date.strftime('%m/%d/%y')\n",
    "        rms['Launch date'] = template_date.strftime('%m/%d/%y')\n",
    "        rms[\"Content deadline\"] = pd.to_datetime(rms[\"Content deadline\"]).dt.normalize()\n",
    "        rms[\"Launch date\"] = pd.to_datetime(rms[\"Launch date\"]).dt.normalize()\n",
    "        rms[\"Content deadline\"] = rms[\"Content deadline\"].astype(str) \n",
    "        rms[\"Launch date\"] = rms[\"Launch date\"].astype(str)\n",
    "        template = pd.read_excel('resources/Booklist_SearchTemplate.xlsx')\n",
    "        rms_upload = pd.DataFrame(np.concatenate([template, rms.values]), columns=template.columns)        \n",
    "        rms_upload.to_excel(save_file, engine='xlsxwriter', index=False)\n",
    "\n",
    "def match(df,save_file):\n",
    "    #open rights request export\n",
    "\n",
    "    \n",
    "\n",
    "    # morning match\n",
    "    # df2 US approvals \n",
    "    # filters to instituition NetSuite or Akademos, Institution country US, and dist set Reseller US (USD)\n",
    "    df2 = df.loc[(df[\"Institution\"].str.contains(\"NetSuite\") | df[\"Institution\"].str.contains( \"Akademos\")) &\n",
    "                    (df[\"Institution's Country\"] == \"US\") &\n",
    "                    (df['Already In'].str.contains(r'Reseller\\s-\\sUS\\s\\(USD\\)') & df['Already In'].notnull())]\n",
    "\n",
    "    # df3 CA approvals\n",
    "    # filters to instituition NetSuite or Bookware, Institution country CA, and dist set Reseller CA (CAD)\n",
    "    df3 = df.loc[(df[\"Institution\"].str.contains(\"NetSuite\") | df[\"Institution\"].str.contains( \"Bookware\")) &\n",
    "                    (df[\"Institution's Country\"] == \"CA\") &\n",
    "                    (df['Already In'].str.contains(r'Reseller\\s-\\sCA\\s\\(CAD\\)') & df['Already In'].notnull())]\n",
    "\n",
    "    # df4 US denials\n",
    "    # filters to instituition NetSuite, Institution country US, and dist set Exclusion set: unavailable to US resellers\n",
    "    df4 = df.loc[(df[\"Institution\"].str.contains(\"NetSuite\")  &\n",
    "                    (df[\"Institution's Country\"] == \"US\") &\n",
    "                    (df['Already In'].str.contains(r'Exclusion\\s+set:\\s+unavailable\\s+to\\s+US\\s+resellers') & df['Already In'].notnull()))]\n",
    "\n",
    "    # df5 CA denials\n",
    "    # filters to instituition NetSuite or Bookware, Institution country CA, and dist set Exclusion set: unavailable to CA resellers\n",
    "    df5 = df.loc[(df[\"Institution\"].str.contains(\"NetSuite\") | df[\"Institution\"].str.contains( \"Bookware\")) &\n",
    "                    (df[\"Institution's Country\"] == \"CA\") &\n",
    "                    (df['Already In'].str.contains(r'Exclusion\\s+set:\\s+unavailable\\s+to\\s+CA\\s+resellers') & df['Already In'].notnull())]\n",
    "\n",
    "    # add status and denial reason code for morning match\n",
    "    df2 = df2.assign(**{'Change Status To': 'Approved'}) #.assign is used add the values to the  column\n",
    "    df3 = df3.assign(**{'Change Status To': 'Approved'})\n",
    "    df4 = df4.assign(**{'Change Status To': 'Denied'})\n",
    "    df4 = df4.assign(**{'Denial Reason Code': '5'})\n",
    "    df5 = df5.assign(**{'Change Status To': 'Denied'})\n",
    "    df5 = df5.assign(**{'Denial Reason Code': '5'})\n",
    "    morning_match = pd.concat([df2, df3, df4,df5], ignore_index=True)   #.concat is used to combine the dataframes\n",
    "    matches_to_remove = morning_match.assign(**{'Change Status To': ''}) \n",
    "    matches_to_remove = matches_to_remove.assign(**{'Denial Reason Code': ''})\n",
    "\n",
    "    find_my_friends = df[~df.isin(matches_to_remove)].dropna(how='all') #.isin is used to remove the rows that are in matches_to_remove\n",
    "\n",
    "    #find my friends\n",
    "    # separate requests by status\n",
    "    nm_oh = find_my_friends.loc[(df['Request Status'] == 'NEEDS_MATCH')|(df['Request Status'] =='ON_HOLD')]\n",
    "    nm_oh = nm_oh[['VBID','Request Status','Most Recent Comment']]\n",
    "    new = find_my_friends.loc[(df['Request Status'] == 'NEW')]\n",
    "    new = new[['VBID','Request Status','Most Recent Comment']]\n",
    "    other = find_my_friends.loc[(df['Request Status'] == 'PROCESSING')|(df['Request Status'] == 'WAITING_LEGAL')|(df['Request Status'] == 'WAITING_PUBLISHER')|(df['Request Status'] == 'WAITING_INSTITUTION')]\n",
    "    other = other[['VBID','Request Status','Most Recent Comment']]\n",
    "\n",
    "\n",
    "\n",
    "    new_nm = pd.merge(new,nm_oh,how='outer',on='VBID',indicator=True)\n",
    "    new_nm = new_nm.loc[new_nm['_merge'] == 'both']\n",
    "    new_nm = new_nm.drop(columns=['Request Status_y','Most Recent Comment_y','_merge'])\n",
    "    new_nm = new_nm.rename(columns={'Request Status_x':'Change Status To','Most Recent Comment_x':'Comment'})\n",
    "\n",
    "    other_nm = pd.merge(other,nm_oh,how='outer',on='VBID',indicator=True)\n",
    "    other_nm = other_nm.loc[other_nm['_merge'] == 'both']\n",
    "    other_nm = other_nm.drop(columns=['Request Status_y','Most Recent Comment_y','_merge'])\n",
    "    other_nm = other_nm.rename(columns={'Request Status_x':'Change Status To','Most Recent Comment_x':'Comment'})\n",
    "\n",
    "    others = other.drop(other[other['Request Status'] == 'WAITING_PUBLISHER'].index)\n",
    "\n",
    "    new_other = pd.merge(new,others,how='outer',on='VBID',indicator=True)\n",
    "    new_other = new_other.loc[new_other['_merge'] == 'both']\n",
    "    new_other = new_other.drop(columns=['Request Status_y','Most Recent Comment_y','_merge'])\n",
    "    new_other = new_other.rename(columns={'Request Status_x':'Change Status To','Most Recent Comment_x':'Comment'})\n",
    "\n",
    "    friends = pd.concat([new_nm,other_nm,new_other],ignore_index=True)\n",
    "    friends = friends.drop_duplicates(subset=['VBID'],keep='first')\n",
    "\n",
    "    find_friends = pd.merge(friends,df,how='outer',on='VBID',indicator=True)\n",
    "    find_friends = find_friends.loc[find_friends['_merge'] == 'both']\n",
    "    find_friends = find_friends.drop(columns=['Change Status To_y','Comment_y','_merge'])\n",
    "    find_friends = find_friends.rename(columns={'Change Status To_x':'Change Status To','Comment_x':'Comment'})\n",
    "    cols = list(find_friends.columns)\n",
    "    cols.insert(4, cols.pop(0))\n",
    "    cols.insert(3, cols.pop(1))\n",
    "    find_friends = find_friends[cols]\n",
    "\n",
    "    mask = find_friends['Change Status To'] == find_friends['Request Status']\n",
    "    find_friends = find_friends.loc[~mask]\n",
    "\n",
    "    fmf_mm = pd.concat([morning_match,find_friends],ignore_index=True)\n",
    "\n",
    "    # export to excel\n",
    "    fmf_mm.to_excel(save_file, engine='xlsxwriter',index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "looker_button = tk.Button(root,text=\"Prepare Looker Booklist\", command=lambda:Thread(target=open_looker_button).start())\n",
    "looker_button.grid(row=0,column=0)\n",
    "fmf_button = tk.Button(root,text=\"Find My Friends/Morning Match\", command=lambda:Thread(target=open_fmf_button).start())\n",
    "fmf_button.grid(row=1,column=0)\n",
    "close_button = tk.Button(root,text=\"EXIT\", command=lambda: root.destroy())\n",
    "close_button.grid(row=2,column=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "w = 250\n",
    "h = 100\n",
    "screen_width = root.winfo_screenwidth()  # Width of the screen\n",
    "screen_height = root.winfo_screenheight() # Height of the screen\n",
    " \n",
    "# Calculate Starting X and Y coordinates for Window\n",
    "x = (screen_width/2) - (w/2)\n",
    "y = (screen_height/2) - (h/2)\n",
    " \n",
    "root.geometry('%dx%d+%d+%d' % (w, h, x, y))\n",
    "root.grid_rowconfigure(0,weight=1)\n",
    "root.grid_columnconfigure(0,weight=1)\n",
    "root.configure(background='black')\n",
    "root.title('Morning Routines')\n",
    "root.mainloop()\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c98fc51-9aee-4797-8086-2e01dba7bb24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
